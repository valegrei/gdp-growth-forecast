{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%xmode Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../libs/\")\n",
    "sys.path.append(\"../../../deep-belief-network/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import shift_join_data, print_hp, flatten\n",
    "from keras_tuner import HyperModel, Objective\n",
    "import datetime\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "from dbn.models import SupervisedDBNRegression\n",
    "from keras_tuner.oracles import RandomSearchOracle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/wb_dataset_prep.csv')\n",
    "df = df.drop('country',axis=1)\n",
    "iso = df['iso'].unique()    #Codigos de paises\n",
    "df = df.set_index(['iso','year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_test = ['PER']\n",
    "iso_train = iso[(iso != iso_test[0])]\n",
    "target_col = ['rgdp_growth']\n",
    "features = df.columns[(df.columns!=target_col[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = df.loc[iso_train][features].copy()\n",
    "df_y_train = df.loc[iso_train][target_col].copy()\n",
    "\n",
    "scaler_x_train = StandardScaler()\n",
    "scaler_y_train = StandardScaler()\n",
    "\n",
    "df_x_train.iloc[:,:] = scaler_x_train.fit_transform(df_x_train)\n",
    "df_y_train.iloc[:,:] = scaler_y_train.fit_transform(df_y_train)\n",
    "\n",
    "df_x_train.iloc[:,:] = np.clip(df_x_train,-5,5)\n",
    "df_y_train.iloc[:,:] = np.clip(df_y_train,-5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caracteristicas pasadas y futuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 10\n",
    "n_steps_out = 3\n",
    "x_s,y_s = shift_join_data(df_x_train, df_y_train, iso_train, n_steps_in, n_steps_out)\n",
    "x_s = flatten(x_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBNHyperModel(HyperModel):\n",
    "\n",
    "    def build(self, hp):\n",
    "        print(\"Pasa aqui 1\")\n",
    "        # Parametrizamos nro de capas, nro de nodos y ratio de aprendizaje\n",
    "        hp_rbm_layers = hp.Int('rbm_layers',1,3,step=1)\n",
    "        hp_rbm_nodes = hp.Int('rbm_nodes',96,356,step=16)\n",
    "        h_layers_structure = [hp_rbm_nodes for i in range(hp_rbm_layers)]\n",
    "        hp_rbm_learning_rate = hp.Choice('rbm_learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "        hp_activation = hp.Choice('activation', values=['relu','tanh'])\n",
    "        hp_n_epochs = hp.Int('rbm_epochs',10,30,step=10)\n",
    "        n_iter_backprop = 100\n",
    "        mini_batch = 32\n",
    "\n",
    "        return SupervisedDBNRegression(\n",
    "            hidden_layers_structure = h_layers_structure,\n",
    "            learning_rate_rbm = hp_rbm_learning_rate,\n",
    "            learning_rate = hp_learning_rate,\n",
    "            n_epochs_rbm = hp_n_epochs,\n",
    "            n_iter_backprop = n_iter_backprop,\n",
    "            batch_size = mini_batch,\n",
    "            activation_function = hp_activation\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_out = 3\n",
    "n_features = len(features)\n",
    "ajuste_path = os.path.normpath('G:/')\n",
    "fecha_hora = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
    "objective = Objective('score','min')\n",
    "max_trials = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 14m 05s]\n",
      "score: 0.4424203869486682\n",
      "\n",
      "Best score So Far: 0.4424203869486682\n",
      "Total elapsed time: 00h 29m 57s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "name_prj = 'DBN'+'_'+fecha_hora\n",
    "dbn_hypermodel = DBNHyperModel()\n",
    "\n",
    "dbn_tuner = kt.SklearnTuner(\n",
    "    hypermodel = dbn_hypermodel,\n",
    "    oracle= RandomSearchOracle(\n",
    "        objective = objective,\n",
    "        max_trials = max_trials\n",
    "    ),\n",
    "    scoring = metrics.make_scorer(metrics.mean_squared_error),\n",
    "    cv = TimeSeriesSplit(n_splits=5),\n",
    "    directory = ajuste_path,\n",
    "    project_name = name_prj,\n",
    "    overwrite=True)\n",
    "\n",
    "dbn_tuner.search(x_s, y_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasa aqui 1\n"
     ]
    }
   ],
   "source": [
    "# guardar mejor modelo\n",
    "output_path = 'ajustes/'\n",
    "best_dbn_hps = dbn_tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "print_hp(output_path+name_prj+'.txt',dbn_tuner)\n",
    "\n",
    "dbn_model = dbn_tuner.hypermodel.build(best_dbn_hps)\n",
    "dbn_model.save(output_path+name_prj+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sys.path.append(\"../libs/\")\n",
    "# from notifications import enviar_correo\n",
    "# enviar_correo(\"Ajuste de Parametros Finalizado!\",\"Se ha completado: {}\".format(name_prj))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6822839c80bb80c42f7f9e096efdd447a89633a8e8a553b5cfb2012f3a4eafe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
