{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%xmode Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../libs/\")\n",
    "sys.path.append(\"../../../deep-belief-network/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import shift_join_data, print_hp, flatten\n",
    "from keras_tuner import HyperModel, Objective\n",
    "import datetime\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "from dbn.models import SupervisedDBNRegression\n",
    "from keras_tuner.oracles import RandomSearchOracle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/wb_dataset_prep.csv')\n",
    "df = df.drop('country',axis=1)\n",
    "iso = df['iso'].unique()    #Codigos de paises\n",
    "df = df.set_index(['iso','year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_test = ['PER']\n",
    "iso_train = iso[(iso != iso_test[0])]\n",
    "target_col = ['rgdp_growth']\n",
    "features = df.columns[(df.columns!=target_col[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = df.loc[iso_train][features].copy()\n",
    "df_y_train = df.loc[iso_train][target_col].copy()\n",
    "\n",
    "scaler_x_train = StandardScaler()\n",
    "scaler_y_train = StandardScaler()\n",
    "\n",
    "df_x_train.iloc[:,:] = scaler_x_train.fit_transform(df_x_train)\n",
    "df_y_train.iloc[:,:] = scaler_y_train.fit_transform(df_y_train)\n",
    "\n",
    "df_x_train.iloc[:,:] = np.clip(df_x_train,-3,3)\n",
    "df_y_train.iloc[:,:] = np.clip(df_y_train,-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caracteristicas pasadas y futuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 10\n",
    "n_steps_out = 3\n",
    "x_s,y_s = shift_join_data(df_x_train, df_y_train, iso_train, n_steps_in, n_steps_out)\n",
    "x_s = flatten(x_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBNHyperModel(HyperModel):\n",
    "\n",
    "    def build(self, hp):\n",
    "        # Parametrizamos nro de capas, nro de nodos y ratio de aprendizaje\n",
    "        hp_rbm_layers = hp.Int('rbm_layers',2,3,step=1)\n",
    "        hp_rbm_nodes = hp.Int('rbm_nodes',96,352,step=16)\n",
    "        h_layers_structure = [hp_rbm_nodes for i in range(hp_rbm_layers)]\n",
    "        hp_activation = hp.Choice('activation', values=['relu','tanh'])\n",
    "        dropout = hp.Float('dropout',0.1,0.5,step=0.1)\n",
    "        rbm_learning_rate = 1e-4\n",
    "        bp_learning_rate = 1e-2\n",
    "        n_epochs = 20\n",
    "        n_iter_backprop = 200\n",
    "        mini_batch = 32\n",
    "\n",
    "        return SupervisedDBNRegression(\n",
    "            hidden_layers_structure = h_layers_structure,\n",
    "            learning_rate_rbm = rbm_learning_rate,\n",
    "            learning_rate = bp_learning_rate,\n",
    "            n_epochs_rbm = n_epochs,\n",
    "            n_iter_backprop = n_iter_backprop,\n",
    "            batch_size = mini_batch,\n",
    "            activation_function = hp_activation,\n",
    "            dropout_p = dropout,\n",
    "            verbose = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_out = 3\n",
    "n_features = len(features)\n",
    "ajuste_path = os.path.normpath('G:/')\n",
    "fecha_hora = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
    "objective = Objective('score','min')\n",
    "max_trials = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 08m 05s]\n",
      "score: 0.8873855240290668\n",
      "\n",
      "Best score So Far: 0.7245706880015204\n",
      "Total elapsed time: 02h 14m 01s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "name_prj = 'DBN'+'_'+fecha_hora\n",
    "dbn_hypermodel = DBNHyperModel()\n",
    "\n",
    "dbn_tuner = kt.SklearnTuner(\n",
    "    hypermodel = dbn_hypermodel,\n",
    "    oracle= RandomSearchOracle(\n",
    "        objective = objective,\n",
    "        max_trials = max_trials\n",
    "    ),\n",
    "    scoring = metrics.make_scorer(metrics.mean_squared_error),\n",
    "    cv = TimeSeriesSplit(n_splits=5),\n",
    "    directory = ajuste_path,\n",
    "    project_name = name_prj,\n",
    "    overwrite=True)\n",
    "\n",
    "dbn_tuner.search(x_s, y_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar mejor modelo\n",
    "output_path = 'ajustes/'\n",
    "best_dbn_hps = dbn_tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "print_hp(output_path+name_prj+'.txt',dbn_tuner)\n",
    "\n",
    "dbn_model = dbn_tuner.hypermodel.build(best_dbn_hps)\n",
    "dbn_model.save(output_path+name_prj+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from notifications import enviar_correo\n",
    "# enviar_correo(\"Ajuste de Parametros Finalizado!\",\"Se ha completado: {}\".format(name_prj))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6822839c80bb80c42f7f9e096efdd447a89633a8e8a553b5cfb2012f3a4eafe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
