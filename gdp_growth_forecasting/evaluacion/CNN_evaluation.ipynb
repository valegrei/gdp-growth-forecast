{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%xmode Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../libs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from utils import shift_join_data, mae,rmse,mape,print_line, plot_pred, plot_history\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del modelo con hiperparametros optimizados (sin entrenar)\n",
    "model_path = '../modelamiento/ajustes/CNN_20220723_1323.h5'\n",
    "# Callback para detener el entrenamiento cuando el error de validacion no disminuye despues de 50 epocas\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=50,restore_best_weights=True)\n",
    "mini_batch = 32\n",
    "n_epochs= 2000  # Nro de epocas maximas\n",
    "fecha_hora = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
    "res_name = 'resultados/CNN_'+fecha_hora\n",
    "n_iter = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/wb_dataset_prep.csv')\n",
    "df = df.drop('country',axis=1)\n",
    "iso = df['iso'].unique()    #Codigos de paises\n",
    "df = df.set_index(['iso','year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEU' 'AUS' 'AUT' 'BGD' 'BEL' 'BOL' 'BRA' 'CAN' 'CHL' 'CHN' 'COL' 'CRI'\n",
      " 'HRV' 'DNK' 'ECU' 'SLV' 'ESP' 'USA' 'EST' 'RUS' 'FIN' 'FRA' 'GRC' 'GTM'\n",
      " 'HND' 'HUN' 'IND' 'IDN' 'IRL' 'ISL' 'ISR' 'ITA' 'JPN' 'JOR' 'KEN' 'LTU'\n",
      " 'LUX' 'MYS' 'MLT' 'MAR' 'MEX' 'NGA' 'NOR' 'NLD' 'PAK' 'PAN' 'PRY' 'PER'\n",
      " 'POL' 'PRT' 'GBR' 'EGY' 'KOR' 'ROU' 'SWE' 'CHE' 'TUR' 'URY' 'NZL']\n"
     ]
    }
   ],
   "source": [
    "print(iso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2444 entries, ('DEU', 1983) to ('NZL', 2021)\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   trade        2444 non-null   float64\n",
      " 1   exports      2444 non-null   float64\n",
      " 2   imports      2444 non-null   float64\n",
      " 3   ggfce        2444 non-null   float64\n",
      " 4   gfcf         2444 non-null   float64\n",
      " 5   unempl       2444 non-null   float64\n",
      " 6   rgdp_growth  2444 non-null   float64\n",
      " 7   infl_cpi     2444 non-null   float64\n",
      " 8   oil          2444 non-null   float64\n",
      " 9   gold         2444 non-null   float64\n",
      " 10  copper       2444 non-null   float64\n",
      " 11  sp500        2444 non-null   float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 239.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_test = ['PER']\n",
    "iso_train = iso[(iso != iso_test[0])]\n",
    "target_col = ['rgdp_growth']\n",
    "features = df.columns[(df.columns!=target_col[0])]\n",
    "df_test = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Países de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEU' 'AUS' 'AUT' 'BGD' 'BEL' 'BOL' 'BRA' 'CAN' 'CHL' 'CHN' 'COL' 'CRI'\n",
      " 'HRV' 'DNK' 'ECU' 'SLV' 'ESP' 'USA' 'EST' 'RUS' 'FIN' 'FRA' 'GRC' 'GTM'\n",
      " 'HND' 'HUN' 'IND' 'IDN' 'IRL' 'ISL' 'ISR' 'ITA' 'JPN' 'JOR' 'KEN' 'LTU'\n",
      " 'LUX' 'MYS' 'MLT' 'MAR' 'MEX' 'NGA' 'NOR' 'NLD' 'PAK' 'PAN' 'PRY' 'POL'\n",
      " 'PRT' 'GBR' 'EGY' 'KOR' 'ROU' 'SWE' 'CHE' 'TUR' 'URY' 'NZL']\n"
     ]
    }
   ],
   "source": [
    "print(iso_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['trade', 'exports', 'imports', 'ggfce', 'gfcf', 'unempl', 'infl_cpi',\n",
      "       'oil', 'gold', 'copper', 'sp500'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = df.loc[iso_train][features].copy()\n",
    "df_y_train = df.loc[iso_train][target_col].copy()\n",
    "df_x_test = df_test.loc[iso_test][features].copy()\n",
    "df_y_test = df_test.loc[iso_test][target_col].copy()\n",
    "\n",
    "std_scaler_x_train = StandardScaler()\n",
    "std_scaler_y_train = StandardScaler()\n",
    "std_scaler_x_test = StandardScaler()\n",
    "std_scaler_y_test = StandardScaler()\n",
    "\n",
    "df_x_train.iloc[:,:] = std_scaler_x_train.fit_transform(df_x_train)\n",
    "df_y_train.iloc[:,:] = std_scaler_y_train.fit_transform(df_y_train)\n",
    "df_x_test.iloc[:,:] = std_scaler_x_test.fit_transform(df_x_test)\n",
    "df_y_test.iloc[:,:] = std_scaler_y_test.fit_transform(df_y_test)\n",
    "\n",
    "df_x_train.iloc[:,:] = np.clip(df_x_train,-3,3)\n",
    "df_y_train.iloc[:,:] = np.clip(df_y_train,-3,3)\n",
    "df_x_test.iloc[:,:] = np.clip(df_x_test,-3,3)\n",
    "df_y_test.iloc[:,:] = np.clip(df_y_test,-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar variables lag y horizonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 9\n",
    "n_steps_out = 3\n",
    "n_features = len(features)\n",
    "\n",
    "x_train, y_train = shift_join_data(df_x_train,df_y_train,iso_train,n_steps_in,n_steps_out)\n",
    "x_test, y_test = shift_join_data(df_x_test,df_y_test,iso_test,n_steps_in,n_steps_out)\n",
    "x_test, y_test = x_test[- int(len(x_test)*0.3):], y_test[- int(len(y_test)*0.3):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_cnn(x_train : np.ndarray, y_train : np.ndarray, x_test : np.ndarray,\n",
    "        y_test : np.ndarray, n_iter : int, scaler : StandardScaler):\n",
    "    n_splits = 5    # Nro de K Folds para CV\n",
    "    res_path = res_name+'.csv'\n",
    "    tscv = TimeSeriesSplit(n_splits = n_splits)\n",
    "    print_line(\"mae_1,mae_2,mae_3,rmse_1,rmse_2,rmse_3,mape_1,mape_2,mape_3\\n\",res_path)\n",
    "    # Inicio\n",
    "    print('Inicio de evaluacion:')\n",
    "    for i in range(n_iter):\n",
    "        val_mae = list()\n",
    "        val_rmse = list()\n",
    "        val_mape = list()\n",
    "        for train_idx, test_idx in tscv.split(x_train):\n",
    "            # CV split\n",
    "            x_t, y_t = x_train[train_idx], y_train[train_idx]\n",
    "            x_v, y_v = x_train[test_idx], y_train[test_idx]\n",
    "            # Entrenamiento\n",
    "            model = load_model(model_path)\n",
    "            model.fit(x_t, y_t, validation_data = (x_v, y_v), epochs = n_epochs,\n",
    "                batch_size = mini_batch, callbacks = [es], shuffle = False, verbose = 0)\n",
    "            # Prediccion\n",
    "            y_pred = model(x_test)\n",
    "            # Denormalizando\n",
    "            dn_y_test = scaler.inverse_transform(y_test)\n",
    "            dn_y_pred = scaler.inverse_transform(y_pred)\n",
    "            # Evaluacion\n",
    "            val_mae.append(mae(dn_y_test, dn_y_pred))\n",
    "            val_rmse.append(rmse(dn_y_test, dn_y_pred))\n",
    "            val_mape.append(mape(dn_y_test, dn_y_pred))\n",
    "        # Promedios\n",
    "        mean_mae = np.mean(val_mae,axis=0)\n",
    "        mean_rmse = np.mean(val_rmse,axis=0)\n",
    "        mean_mape = np.mean(val_mape,axis=0)\n",
    "        print_line('{},{},{},{},{},{},{},{},{}\\n'.format(mean_mae[0],mean_mae[1],mean_mae[2],\n",
    "            mean_rmse[0],mean_rmse[1],mean_rmse[2],mean_mape[0],mean_mape[1],mean_mape[2]),res_path)\n",
    "        print('Iter: {}/{} completado.'.format(i+1,n_iter))\n",
    "    print('Fin de evaluacion.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio de evaluacion:\n",
      "Iter: 1/30 completado.\n"
     ]
    }
   ],
   "source": [
    "# evaluar\n",
    "evaluar_cnn(x_train, y_train, x_test, y_test,n_iter,std_scaler_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv(res_name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[['mae_1','mae_2','mae_3']].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[['rmse_1','rmse_2','rmse_3']].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[['mape_1','mape_2','mape_3']].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path)\n",
    "history = model.fit(x_train, y_train, validation_split = 0.3, epochs = n_epochs,\n",
    "            batch_size = mini_batch, callbacks = [es], shuffle = False, verbose = 0)\n",
    "model.save(res_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history,'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_test)\n",
    "dn_y_test = std_scaler_y_test.inverse_transform(y_test)\n",
    "dn_y_pred = std_scaler_y_test.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(dn_y_test, dn_y_pred,2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,'CNN.png',show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notifications import enviar_correo\n",
    "enviar_correo(\"Evaluacion Finalizado!\",\"Se ha completado: {}\".format(res_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('entornoGPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b5f45148ae3128c6dd6e07223b4f800e24d99a74d72c1203f234d906a82ee07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
