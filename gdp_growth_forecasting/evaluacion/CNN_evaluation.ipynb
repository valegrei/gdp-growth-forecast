{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%xmode Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../libs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from utils import shift_join_data, rmse,mae,mape, print_line, plot_pred\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del modelo con hiperparametros optimizados (sin entrenar)\n",
    "model_path = '../modelamiento/ajustes/CNN_20220723_1323.h5'\n",
    "# Callback para detener el entrenamiento cuando el error de validacion no disminuye despues de 50 epocas\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=50,restore_best_weights=True)\n",
    "mini_batch = 32\n",
    "n_epochs= 2000  # Nro de epocas maximas\n",
    "fecha_hora = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
    "res_name = 'resultados/CNN_'+fecha_hora\n",
    "n_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notification\n",
    "from getpass import getpass \n",
    "email = 'valegrei@outlook.com'\n",
    "passwd = getpass('passwd:')\n",
    "to_addr = 'victoralegre@uni.pe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/wb_dataset_prep.csv')\n",
    "df = df.drop('country',axis=1)\n",
    "iso = df['iso'].unique()    #Codigos de paises\n",
    "df = df.set_index(['iso','year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEU' 'AUS' 'AUT' 'BGD' 'BEL' 'BOL' 'BRA' 'CAN' 'CHL' 'CHN' 'COL' 'CRI'\n",
      " 'HRV' 'DNK' 'ECU' 'SLV' 'ESP' 'USA' 'EST' 'RUS' 'FIN' 'FRA' 'GRC' 'GTM'\n",
      " 'HND' 'HUN' 'IND' 'IDN' 'IRL' 'ISL' 'ISR' 'ITA' 'JPN' 'JOR' 'KEN' 'LTU'\n",
      " 'LUX' 'MYS' 'MLT' 'MAR' 'MEX' 'NGA' 'NOR' 'NLD' 'PAK' 'PAN' 'PRY' 'PER'\n",
      " 'POL' 'PRT' 'GBR' 'EGY' 'KOR' 'ROU' 'SWE' 'CHE' 'TUR' 'URY' 'NZL']\n"
     ]
    }
   ],
   "source": [
    "print(iso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2444 entries, ('DEU', 1983) to ('NZL', 2021)\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   trade        2444 non-null   float64\n",
      " 1   exports      2444 non-null   float64\n",
      " 2   imports      2444 non-null   float64\n",
      " 3   ggfce        2444 non-null   float64\n",
      " 4   gfcf         2444 non-null   float64\n",
      " 5   unempl       2444 non-null   float64\n",
      " 6   rgdp_growth  2444 non-null   float64\n",
      " 7   infl_cpi     2444 non-null   float64\n",
      " 8   oil          2444 non-null   float64\n",
      " 9   gold         2444 non-null   float64\n",
      " 10  copper       2444 non-null   float64\n",
      " 11  sp500        2444 non-null   float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 239.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_test = ['PER']\n",
    "iso_train = iso[(iso != iso_test[0])]\n",
    "target_col = ['rgdp_growth']\n",
    "features = df.columns[(df.columns!=target_col[0])]\n",
    "df_test = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Países de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEU' 'AUS' 'AUT' 'BGD' 'BEL' 'BOL' 'BRA' 'CAN' 'CHL' 'CHN' 'COL' 'CRI'\n",
      " 'HRV' 'DNK' 'ECU' 'SLV' 'ESP' 'USA' 'EST' 'RUS' 'FIN' 'FRA' 'GRC' 'GTM'\n",
      " 'HND' 'HUN' 'IND' 'IDN' 'IRL' 'ISL' 'ISR' 'ITA' 'JPN' 'JOR' 'KEN' 'LTU'\n",
      " 'LUX' 'MYS' 'MLT' 'MAR' 'MEX' 'NGA' 'NOR' 'NLD' 'PAK' 'PAN' 'PRY' 'POL'\n",
      " 'PRT' 'GBR' 'EGY' 'KOR' 'ROU' 'SWE' 'CHE' 'TUR' 'URY' 'NZL']\n"
     ]
    }
   ],
   "source": [
    "print(iso_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['trade', 'exports', 'imports', 'ggfce', 'gfcf', 'unempl', 'infl_cpi',\n",
      "       'oil', 'gold', 'copper', 'sp500'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = df.loc[iso_train][features].copy()\n",
    "df_y_train = df.loc[iso_train][target_col].copy()\n",
    "df_x_test = df_test.loc[iso_test][features].copy()\n",
    "df_y_test = df_test.loc[iso_test][target_col].copy()\n",
    "\n",
    "std_scaler_x_train = StandardScaler()\n",
    "std_scaler_y_train = StandardScaler()\n",
    "std_scaler_x_test = StandardScaler()\n",
    "std_scaler_y_test = StandardScaler()\n",
    "\n",
    "df_x_train.iloc[:,:] = std_scaler_x_train.fit_transform(df_x_train)\n",
    "df_y_train.iloc[:,:] = std_scaler_y_train.fit_transform(df_y_train)\n",
    "df_x_test.iloc[:,:] = std_scaler_x_test.fit_transform(df_x_test)\n",
    "df_y_test.iloc[:,:] = std_scaler_y_test.fit_transform(df_y_test)\n",
    "\n",
    "df_x_train.iloc[:,:] = np.clip(df_x_train,-3,3)\n",
    "df_y_train.iloc[:,:] = np.clip(df_y_train,-3,3)\n",
    "df_x_test.iloc[:,:] = np.clip(df_x_test,-3,3)\n",
    "df_y_test.iloc[:,:] = np.clip(df_y_test,-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar variables lag y horizonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gold_t-0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/frame.py:3799\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3798\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3799\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_info_axis\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3800\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   3801\u001b[0m     \u001b[39m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3631\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3632\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3633\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3634\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gold_t-0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/luis/Documentos/gdp-growth-forecast/gdp_growth_forecasting/evaluacion/CNN_evaluation.ipynb Celda 22\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luis/Documentos/gdp-growth-forecast/gdp_growth_forecasting/evaluacion/CNN_evaluation.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m n_steps_out \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luis/Documentos/gdp-growth-forecast/gdp_growth_forecasting/evaluacion/CNN_evaluation.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m n_features \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(features)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/luis/Documentos/gdp-growth-forecast/gdp_growth_forecasting/evaluacion/CNN_evaluation.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m x_train, y_train \u001b[39m=\u001b[39m shift_join_data(df_x_train,df_y_train,iso_train,n_steps_in,n_steps_out)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luis/Documentos/gdp-growth-forecast/gdp_growth_forecasting/evaluacion/CNN_evaluation.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m x_test, y_test \u001b[39m=\u001b[39m shift_join_data(df_x_test,df_y_test,iso_test,n_steps_in,n_steps_out)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luis/Documentos/gdp-growth-forecast/gdp_growth_forecasting/evaluacion/CNN_evaluation.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m x_test, y_test \u001b[39m=\u001b[39m x_test[\u001b[39m-\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(x_test)\u001b[39m*\u001b[39m\u001b[39m0.2\u001b[39m):], y_test[\u001b[39m-\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(y_test)\u001b[39m*\u001b[39m\u001b[39m0.2\u001b[39m):]\n",
      "File \u001b[0;32m~/Documentos/gdp-growth-forecast/gdp_growth_forecasting/evaluacion/../libs/utils.py:119\u001b[0m, in \u001b[0;36mshift_join_data\u001b[0;34m(df_x, df_y, indexes, n_steps_in, n_steps_out)\u001b[0m\n\u001b[1;32m    116\u001b[0m x, y \u001b[39m=\u001b[39m shift_data(df_x\u001b[39m.\u001b[39mloc[indexes[\u001b[39m0\u001b[39m]], df_y\u001b[39m.\u001b[39mloc[indexes[\u001b[39m0\u001b[39m]],\n\u001b[1;32m    117\u001b[0m                   n_steps_in, n_steps_out)\n\u001b[1;32m    118\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(indexes)):\n\u001b[0;32m--> 119\u001b[0m     x_i, y_i \u001b[39m=\u001b[39m shift_data(\n\u001b[1;32m    120\u001b[0m         df_x\u001b[39m.\u001b[39;49mloc[indexes[i]], df_y\u001b[39m.\u001b[39;49mloc[indexes[i]], n_steps_in, n_steps_out)\n\u001b[1;32m    121\u001b[0m     x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((x, x_i))\n\u001b[1;32m    122\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((y, y_i))\n",
      "File \u001b[0;32m~/Documentos/gdp-growth-forecast/gdp_growth_forecasting/evaluacion/../libs/utils.py:72\u001b[0m, in \u001b[0;36mshift_data\u001b[0;34m(df_x, df_y, n_steps_in, n_steps_out)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m# Lag features\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_steps_in\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m     data_shifted[features \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_t-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m     73\u001b[0m                  \u001b[39mstr\u001b[39m(n_steps_in\u001b[39m-\u001b[39mt)] \u001b[39m=\u001b[39m data_shifted[features]\u001b[39m.\u001b[39mshift(n_steps_in\u001b[39m-\u001b[39mt)\n\u001b[1;32m     74\u001b[0m     x_cols \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39mx_cols, \u001b[39m*\u001b[39m((features \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_t-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(n_steps_in\u001b[39m-\u001b[39mt))\u001b[39m.\u001b[39mtolist())]\n\u001b[1;32m     75\u001b[0m \u001b[39m# Future features\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/frame.py:3643\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3641\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_frame(key, value)\n\u001b[1;32m   3642\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (Series, np\u001b[39m.\u001b[39mndarray, \u001b[39mlist\u001b[39m, Index)):\n\u001b[0;32m-> 3643\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_array(key, value)\n\u001b[1;32m   3644\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   3645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/frame.py:3687\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3685\u001b[0m     check_key_length(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, key, value)\n\u001b[1;32m   3686\u001b[0m     \u001b[39mfor\u001b[39;00m k1, k2 \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(key, value\u001b[39m.\u001b[39mcolumns):\n\u001b[0;32m-> 3687\u001b[0m         \u001b[39mself\u001b[39m[k1] \u001b[39m=\u001b[39m value[k2]\n\u001b[1;32m   3689\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(value):\n\u001b[1;32m   3690\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m key:\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/frame.py:3845\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3842\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[1;32m   3843\u001b[0m             value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtile(value, (\u001b[39mlen\u001b[39m(existing_piece\u001b[39m.\u001b[39mcolumns), \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mT\n\u001b[0;32m-> 3845\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item_mgr(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/frame.py:3802\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3799\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   3800\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   3801\u001b[0m     \u001b[39m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49minsert(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_info_axis), key, value)\n\u001b[1;32m   3803\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iset_item_mgr(loc, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/internals/managers.py:1240\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[0;34m(self, loc, item, value)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \u001b[39mInsert item at selected position.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[39mvalue : np.ndarray or ExtensionArray\u001b[39;00m\n\u001b[1;32m   1238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m \u001b[39m# insert to the axis; this could possibly raise a TypeError\u001b[39;00m\n\u001b[0;32m-> 1240\u001b[0m new_axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems\u001b[39m.\u001b[39;49minsert(loc, item)\n\u001b[1;32m   1242\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1243\u001b[0m     value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/indexes/base.py:6630\u001b[0m, in \u001b[0;36mIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   6628\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor\u001b[39m.\u001b[39m_with_infer(new_values, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   6629\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 6630\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39;49m_with_infer(new_values, name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/indexes/base.py:680\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    679\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.*the Index constructor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 680\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m _dtype_obj \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_is_multi:\n\u001b[1;32m    683\u001b[0m     \u001b[39m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[1;32m    685\u001b[0m     \u001b[39m# \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     values \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result\u001b[39m.\u001b[39m_values)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cudaEnv/lib/python3.9/site-packages/pandas/core/indexes/base.py:472\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m    467\u001b[0m     \u001b[39misinstance\u001b[39m(data, Index)\n\u001b[1;32m    468\u001b[0m     \u001b[39mand\u001b[39;00m data\u001b[39m.\u001b[39m_is_backward_compat_public_numeric_index\n\u001b[1;32m    469\u001b[0m     \u001b[39mand\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    470\u001b[0m ):\n\u001b[1;32m    471\u001b[0m     \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39m_constructor(data, name\u001b[39m=\u001b[39mname, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m--> 472\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(data, (np\u001b[39m.\u001b[39;49mndarray, Index, ABCSeries)):\n\u001b[1;32m    474\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ABCMultiIndex):\n\u001b[1;32m    475\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39m_values\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_steps_in = 9\n",
    "n_steps_out = 3\n",
    "n_features = len(features)\n",
    "\n",
    "x_train, y_train = shift_join_data(df_x_train,df_y_train,iso_train,n_steps_in,n_steps_out)\n",
    "x_test, y_test = shift_join_data(df_x_test,df_y_test,iso_test,n_steps_in,n_steps_out)\n",
    "x_test, y_test = x_test[- int(len(x_test)*0.2):], y_test[- int(len(y_test)*0.2):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_cnn(x_train : np.ndarray, y_train : np.ndarray, x_test : np.ndarray,\n",
    "        y_test : np.ndarray, n_iter : int, scaler : StandardScaler):\n",
    "    n_splits = 5    # Nro de K Folds para CV\n",
    "    res_path = res_name+'.csv'\n",
    "    tscv = TimeSeriesSplit(n_splits = n_splits)\n",
    "    print_line(\"rmse,mae,mape\\n\",res_path)\n",
    "    # Inicio\n",
    "    gl_rmse = list()\n",
    "    nro = 0\n",
    "    print('Inicio de evaluacion:')\n",
    "    for i in range(n_iter):\n",
    "        val_rmse = list()\n",
    "        val_mae = list()\n",
    "        val_mape = list()\n",
    "        for train_idx, test_idx in tscv.split(x_train):\n",
    "            # CV split\n",
    "            x_t, y_t = x_train[train_idx], y_train[train_idx]\n",
    "            x_v, y_v = x_train[test_idx], y_train[test_idx]\n",
    "            # Entrenamiento\n",
    "            model = load_model(model_path)\n",
    "            model.fit(x_t, y_t, validation_data = (x_v, y_v), epochs = n_epochs,\n",
    "                batch_size = mini_batch, callbacks = [es], shuffle = False, verbose = 0)\n",
    "            # Prediccion\n",
    "            y_pred = model(x_test)\n",
    "            # Denormalizando\n",
    "            dn_y_test = scaler.inverse_transform(y_test)\n",
    "            dn_y_pred = scaler.inverse_transform(y_pred)\n",
    "            # Evaluacion\n",
    "            val_rmse.append(rmse(dn_y_test, dn_y_pred))\n",
    "            val_mae.append(mae(dn_y_test, dn_y_pred))\n",
    "            val_mape.append(mape(dn_y_test, dn_y_pred))\n",
    "            gl_rmse.append(rmse(dn_y_test, dn_y_pred))\n",
    "            model.save(f'{res_name}_{nro}.h5')\n",
    "            nro += 1\n",
    "        # Promedios\n",
    "        mean_rmse = np.mean(val_rmse)\n",
    "        print_line(f'{mean_rmse},{mean_mae},{mean_mape}\\n',res_path)\n",
    "        print(f'Iter: {(i+1)}/{n_iter} completado.')\n",
    "    print('Fin de evaluacion.')\n",
    "    mejor_modelo = np.argmin(gl_rmse)\n",
    "    print('Mejor modelo: {}'.format(mejor_modelo))\n",
    "    return mejor_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluar\n",
    "nro_mejor = evaluar_cnn(x_train, y_train, x_test, y_test,n_iter,std_scaler_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv(res_name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_res.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(res_name+'_'+str(nro_mejor)+'.h5')\n",
    "#model = load_model('resultados/CNN_20220731_1050_1.h5')\n",
    "y_pred = model(x_test)\n",
    "dn_y_test = std_scaler_y_test.inverse_transform(y_test)\n",
    "dn_y_pred = std_scaler_y_test.inverse_transform(y_pred)\n",
    "plot_pred(dn_y_test, dn_y_pred,2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model,'CNN.png',show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notifications import enviar_correo\n",
    "enviar_correo(email,passwd,email,to_addr,\"Evaluacion Finalizado!\",\"Se ha completado: {}\".format(res_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cudaEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44755a657f09dfe811136a26eb2d4fde13a04db75411546a56f167017bc624af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
